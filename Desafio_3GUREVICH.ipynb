{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meligurevich/IAPH/blob/main/Desafio_3GUREVICH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MELISA SABRINA GUREVICH\n",
        "\n",
        "DNI: 35.365.884"
      ],
      "metadata": {
        "id": "VqZqH1hHwgu9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq6j8LsYq1Dr"
      },
      "source": [
        "### Vectorización de texto y modelo de clasificación Naïve Bayes con el dataset 20 newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7cXR6CI30ry"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 20newsgroups por ser un dataset clásico de NLP ya viene incluido y formateado\n",
        "# en sklearn\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD-pVDWV_rQc"
      },
      "source": [
        "## Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ech9qJaUo9vK"
      },
      "outputs": [],
      "source": [
        "# cargamos los datos (ya separados de forma predeterminada en train y test)\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxjSI7su_uWI"
      },
      "source": [
        "## Vectorización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-94VP0QYCzDn"
      },
      "outputs": [],
      "source": [
        "# instanciamos un vectorizador\n",
        "# ver diferentes parámetros de instanciación en la documentación de sklearn\n",
        "tfidfvect = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ftPlyanuak8n",
        "outputId": "b1e00b98-4b16-4148-f4d8-c00d2a323cca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# en el atributo `data` accedemos al texto\n",
        "newsgroups_train.data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zxcXV6aC_oL"
      },
      "outputs": [],
      "source": [
        "# con la interfaz habitual de sklearn podemos fitear el vectorizador\n",
        "# (obtener el vocabulario y calcular el vector IDF)\n",
        "# y transformar directamente los datos\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "# `X_train` la podemos denominar como la matriz documento-término"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Sv7TXbda41-",
        "outputId": "0f5faaab-d604-4dad-b0cf-57ae4f112303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n",
            "shape: (11314, 101631)\n",
            "cantidad de documentos: 11314\n",
            "tamaño del vocabulario (dimensionalidad de los vectores): 101631\n"
          ]
        }
      ],
      "source": [
        "# recordar que las vectorizaciones por conteos son esparsas\n",
        "# por ello sklearn convenientemente devuelve los vectores de documentos\n",
        "# como matrices esparsas\n",
        "print(type(X_train))\n",
        "print(f'shape: {X_train.shape}')\n",
        "print(f'cantidad de documentos: {X_train.shape[0]}')\n",
        "print(f'tamaño del vocabulario (dimensionalidad de los vectores): {X_train.shape[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgydNTZ2pAgR",
        "outputId": "74c47240-85a6-43a2-ceb0-9e62b5b8ca54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25775"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# una vez ajustado el vectorizador, podemos acceder a atributos como el vocabulario\n",
        "# aprendido. Es un diccionario que va de términos a índices.\n",
        "# El índice es la posición en el vector de documento.\n",
        "tfidfvect.vocabulary_['car']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnTSZuvyrTcP"
      },
      "outputs": [],
      "source": [
        "# es muy útil tener el diccionario opuesto que va de índices a términos\n",
        "idx2word = {v: k for k,v in tfidfvect.vocabulary_.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swa-AgWrMSHM",
        "outputId": "31e4eb4d-2e57-45d3-f2f1-a64938e86abb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# en `y_train` guardamos los targets que son enteros\n",
        "y_train = newsgroups_train.target\n",
        "y_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je5kxvQMDLvf",
        "outputId": "895b85fe-75a6-4642-dd15-30525359cdac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clases [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# hay 20 clases correspondientes a los 20 grupos de noticias\n",
        "print(f'clases {np.unique(newsgroups_test.target)}')\n",
        "newsgroups_test.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXCICFSd_y90"
      },
      "source": [
        "## Similaridad de documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pki_olShnyE",
        "outputId": "1257269f-a91b-4f78-91a7-072e4777426d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THE WHITE HOUSE\n",
            "\n",
            "                  Office of the Press Secretary\n",
            "                   (Pittsburgh, Pennslyvania)\n",
            "______________________________________________________________\n",
            "For Immediate Release                         April 17, 1993     \n",
            "\n",
            "             \n",
            "                  RADIO ADDRESS TO THE NATION \n",
            "                        BY THE PRESIDENT\n",
            "             \n",
            "                Pittsburgh International Airport\n",
            "                    Pittsburgh, Pennsylvania\n",
            "             \n",
            "             \n",
            "10:06 A.M. EDT\n",
            "             \n",
            "             \n",
            "             THE PRESIDENT:  Good morning.  My voice is coming to\n",
            "you this morning through the facilities of the oldest radio\n",
            "station in America, KDKA in Pittsburgh.  I'm visiting the city to\n",
            "meet personally with citizens here to discuss my plans for jobs,\n",
            "health care and the economy.  But I wanted first to do my weekly\n",
            "broadcast with the American people. \n",
            "             \n",
            "             I'm told this station first broadcast in 1920 when\n",
            "it reported that year's presidential elections.  Over the past\n",
            "seven decades presidents have found ways to keep in touch with\n",
            "the people, from whistle-stop tours to fire-side chats to the bus\n",
            "tour that I adopted, along with Vice President Gore, in last\n",
            "year's campaign.\n",
            "             \n",
            "             Every Saturday morning I take this time to talk with\n",
            "you, my fellow Americans, about the problems on your minds and\n",
            "what I'm doing to try and solve them.  It's my way of reporting\n",
            "to you and of giving you a way to hold me accountable.\n",
            "             \n",
            "             You sent me to Washington to get our government and\n",
            "economy moving after years of paralysis and policy and a bad\n",
            "experiment with trickle-down economics.  You know how important\n",
            "it is for us to make bold, comprehensive changes in the way we do\n",
            "business.  \n",
            "             \n",
            "             We live in a competitive global economy.  Nations\n",
            "rise and fall on the skills of their workers, the competitiveness\n",
            "of their companies, the imagination of their industries, and the\n",
            "cooperative experience and spirit that exists between business,\n",
            "labor and government.  Although many of the economies of the\n",
            "industrialized world are now suffering from slow growth, they've\n",
            "made many of the smart investments and the tough choices which\n",
            "our government has for too long ignored.  That's why many of them\n",
            "have been moving ahead and too many of our people have been\n",
            "falling behind.\n",
            "             \n",
            "             We have an economy today that even when it grows is\n",
            "not producing new jobs.  We've increased the debt of our nation\n",
            "by four times over the last 12 years, and we don't have much to\n",
            "show for it.  We know that wages of most working people have\n",
            "stopped rising, that most people are working longer work weeks\n",
            "and that too many families can no longer afford the escalating\n",
            "cost of health care.\n",
            "             \n",
            "             But we also know that, given the right tools, the\n",
            "right incentives and the right encouragement, our workers and\n",
            "businesses can make the kinds of products and profits our economy\n",
            "needs to expand opportunity and to make our communities better\n",
            "places to live.\n",
            "             \n",
            "             In many critical products today Americans are the\n",
            "low cost, high quality producers.  Our task is to make sure that\n",
            "we create more of those kinds of jobs.\n",
            "             \n",
            "             Just two months ago I gave Congress my plan for\n",
            "long-term jobs and economic growth.  It changes the old\n",
            "priorities in Washington and puts our emphasis where it needs to\n",
            "be -- on people's real needs, on increasing investments and jobs\n",
            "and education, on cutting the federal deficit, on stopping the\n",
            "waste which pays no dividends, and redirecting our precious\n",
            "resources toward investment that creates jobs now and lays the\n",
            "groundwork for robust economic growth in the future.\n",
            "             \n",
            "             These new directions passed the Congress in record\n",
            "time and created a new sense of hope and opportunity in our\n",
            "country.  Then the jobs plan I presented to Congress, which would\n",
            "create hundreds of thousands of jobs, most of them in the private\n",
            "sector in 1993 and 1994, passed the House of Representatives.  It\n",
            "now has the support of a majority of the United States Senate. \n",
            "But it's been held up by a filibuster of a minority in the\n",
            "Senate, just 43 senators.  They blocked a vote that they know\n",
            "would result in the passage of our bill and the creation of jobs.\n",
            "             \n",
            "             The issue isn't politics; the issue is people. \n",
            "Millions of Americans are waiting for this legislation and\n",
            "counting on it, counting on us in Washington.  But the jobs bill\n",
            "has been grounded by gridlock.  \n",
            "             \n",
            "             I know the American people are tired of business as\n",
            "usual and politics as usual.  I know they don't want us to spin\n",
            "or wheels.  They want the recovery to get moving.  So I have\n",
            "taken a first step to break this gridlock and gone the extra\n",
            "mile.  Yesterday I offered to cut the size of this plan by 25\n",
            "percent -- from $16 billion to $12 billion.  \n",
            "             \n",
            "             It's not what I'd hoped for.  With 16 million\n",
            "Americans looking for full-time work, I simply can't let the bill\n",
            "languish when I know that even a compromise bill will mean\n",
            "hundreds of thousands of jobs for our people.  The mandate is to\n",
            "act to achieve change and move the country forward.  By taking\n",
            "this initiative in the face of an unrelenting Senate talkathon, I\n",
            "think we can respond to your mandate and achieve a significant\n",
            "portion of our original goals.\n",
            "             \n",
            "             First, we want to keep the programs as much as\n",
            "possible that are needed to generate jobs and meet human needs,\n",
            "including highway and road construction, summer jobs for young\n",
            "people, immunization for children, construction of waste water\n",
            "sites, and aid to small businesses.  We also want to keep funding\n",
            "for extended unemployment compensation benefits, for people who\n",
            "have been unemployed for a long time because the economy isn't\n",
            "creating jobs.\n",
            "             \n",
            "             Second, I've recommended that all the other programs\n",
            "in the bill be cut across-the-board by a little more than 40\n",
            "percent.\n",
            "             \n",
            "             And third, I've recommended a new element in this\n",
            "program to help us immediately start our attempt to fight against\n",
            "crime by providing $200 million for cities and towns to rehire\n",
            "police officers who lost their jobs during the recession and put\n",
            "them back to work protecting our people.  I'm also going to fight\n",
            "for a tough crime bill because the people of this country need it\n",
            "and deserve it.\n",
            "             \n",
            "             Now, the people who are filibustering this bill --\n",
            "the Republican senators -- say they won't vote for it because it\n",
            "increases deficit spending, because there's extra spending this\n",
            "year that hasn't already been approved.  That sounds reasonable,\n",
            "doesn't it?  Here's what they don't say.  This program is more\n",
            "than paid for by budget cuts over my five-year budget, and this\n",
            "budget is well within the spending limits already approved by the\n",
            "Congress this year.\n",
            "             \n",
            "             It's amazing to me that many of these same senators\n",
            "who are filibustering the bill voted during the previous\n",
            "administration for billions of dollars of the same kind of\n",
            "emergency spending, and much of it was not designed to put the\n",
            "American people to work.  \n",
            "             \n",
            "             This is not about deficit spending.  We have offered\n",
            "a plan to cut the deficit.  This is about where your priorities\n",
            "are -- on people or on politics.  \n",
            "             \n",
            "             Keep in mind that our jobs bill is paid for dollar\n",
            "for dollar.  It is paid for by budget cuts.  And it's the\n",
            "soundest investment we can now make for ourselves and our\n",
            "children.  I urge all Americans to take another look at this jobs\n",
            "and investment program; to consider again the benefits for all of\n",
            "us when we've helped make more American partners working to\n",
            "ensure the future of our nation and the strength of our economy.\n",
            "             \n",
            "             You know, if every American who wanted a job had\n",
            "one, we wouldn't have a lot of the other problems we have in this\n",
            "country today.  This bill is not a miracle, it's a modest first\n",
            "step to try to set off a job creation explosion in this country\n",
            "again.  But it's a step we ought to take.  And it is fully paid\n",
            "for over the life of our budget.\n",
            "             \n",
            "             Tell your lawmakers what you think.  Tell them how\n",
            "important the bill is.  If it passes, we'll all be winners.\n",
            "             \n",
            "             Good morning, and thank you for listening.\n"
          ]
        }
      ],
      "source": [
        "# Veamos similaridad de documentos. Tomemos algún documento\n",
        "idx = 4811\n",
        "print(newsgroups_train.data[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ssa9bqJ-hA_v"
      },
      "outputs": [],
      "source": [
        "# midamos la similaridad coseno con todos los documentos de train\n",
        "cossim = cosine_similarity(X_train[idx], X_train)[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cossim"
      ],
      "metadata": {
        "id": "qQWdijV_-ClO",
        "outputId": "98498d5c-b100-4a77-ad8b-82a6f5f56a9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.1382319 , 0.1067036 , 0.23029327, ..., 0.12320753, 0.08765353,\n",
              "       0.04415046])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_mDA7p3AzcQ",
        "outputId": "8e90817b-1be0-41b0-8cac-417260bb8fc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.70930477, 0.67474953, ..., 0.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# podemos ver los valores de similaridad ordenados de mayor a menos\n",
        "np.sort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OIhDA1jAryX",
        "outputId": "0abbbba9-e9cc-4a30-c90d-d42d9f31136a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4811, 6635, 4253, ..., 9019, 9016, 8748])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# y a qué documentos corresponden\n",
        "np.argsort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hP7qLS4ZBLps"
      },
      "outputs": [],
      "source": [
        "# los 5 documentos más similares:\n",
        "mostsim = np.argsort(cossim)[::-1][1:6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QdJLHPJACvaj",
        "outputId": "b99e3c44-7ab5-4c57-8d11-48ad5793603c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'talk.politics.misc'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# el documento original pertenece a la clase:\n",
        "newsgroups_train.target_names[y_train[idx]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWy_73epCbFG",
        "outputId": "65681905-ebf5-4d6d-87f1-75e8efe62b3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n"
          ]
        }
      ],
      "source": [
        "# y los 5 más similares son de las clases:\n",
        "for i in mostsim:\n",
        "  print(newsgroups_train.target_names[y_train[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRoNnKwhBqzq"
      },
      "source": [
        "### Modelo de clasificación Naïve Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "TPM0thDaLk0R",
        "outputId": "0905baaa-4764-470d-eeef-d06df4e7f2a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# es muy fácil instanciar un modelo de clasificación Naïve Bayes y entrenarlo con sklearn\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrQjzM48Mu4T"
      },
      "outputs": [],
      "source": [
        "# con nuestro vectorizador ya fiteado en train, vectorizamos los textos\n",
        "# del conjunto de test\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_test = newsgroups_test.target\n",
        "y_pred =  clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkGJhetEPdA4",
        "outputId": "ff9b14b6-6901-4373-98cd-a7cfcc9abd24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5854345727938506"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# el F1-score es una metrica adecuada para reportar desempeño de modelos de claificación\n",
        "# es robusta al desbalance de clases. El promediado 'macro' es el promedio de los\n",
        "# F1-score de cada clase. El promedio 'micro' es equivalente a la accuracy que no\n",
        "# es una buena métrica cuando los datasets son desbalanceados\n",
        "f1_score(y_test, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McArD4rSDR2K"
      },
      "source": [
        "### Consigna del desafío 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alumna: Melisa Sabrina Gurevich"
      ],
      "metadata": {
        "id": "sv8kKKGnqBkf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJgf6GQIIEH1"
      },
      "source": [
        "**1**. Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
        "Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido\n",
        "la similaridad según el contenido del texto y la etiqueta de clasificación.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Impprtamos librerías necesarias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Cargamos dataset\n",
        "categories = ['rec.sport.hockey', 'sci.space', 'talk.politics.misc', 'comp.graphics']\n",
        "newsgroups = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'text': newsgroups.data,\n",
        "    'label': [newsgroups.target_names[i] for i in newsgroups.target]\n",
        "})\n",
        "\n",
        "# Vectorizamos textos con CountVectorizer\n",
        "vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n",
        "X = vectorizer.fit_transform(df['text'])\n",
        "\n",
        "# Seleccionamos 5 documentos al azar\n",
        "np.random.seed(42)\n",
        "selected_indices = np.random.choice(len(df), size=5, replace=False)\n",
        "\n",
        "# Calculamos similitud coseno entre documentos\n",
        "similarity_matrix = cosine_similarity(X)\n",
        "\n",
        "# Para cada documento, encontrar los 5 más similares\n",
        "for idx in selected_indices:\n",
        "    print(f\"\\nDocumento original (índice {idx}) - Categoría: {df.iloc[idx]['label']}\")\n",
        "    print(df.iloc[idx]['text'][:300], \"...\")  # Mostrar primeros 300 caracteres\n",
        "\n",
        "    # Calculamos similitud con el resto\n",
        "    sim_scores = similarity_matrix[idx]\n",
        "    sim_scores[idx] = -1  # evitar seleccionar el mismo\n",
        "\n",
        "    # Obtenemos índices de los 5 más similares\n",
        "    top5_idx = np.argsort(sim_scores)[-5:][::-1]\n",
        "\n",
        "    print(\"\\nDocumentos más similares:\")\n",
        "    for i, sim_idx in enumerate(top5_idx):\n",
        "        print(f\"\\n{i+1}. Similitud: {sim_scores[sim_idx]:.3f} - Categoría: {df.iloc[sim_idx]['label']}\")\n",
        "        print(df.iloc[sim_idx]['text'][:200], \"...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFP0Q-UO1Wr5",
        "outputId": "bd94d402-319a-4331-db68-0593aaf2a7c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Documento original (índice 727) - Categoría: comp.graphics\n",
            "Does anyone know the phone number to a place where i can get\n",
            "a VGA passthrough?\n",
            "\n",
            "\tI want to hook up my VGA card to my XGA card (whcih you can can).\n",
            "All I need is the cable that connects them.  It is the same type of\n",
            "cable that you would connect from your VGA card to say a Video Blaster\n",
            "or something. ...\n",
            "\n",
            "Documentos más similares:\n",
            "\n",
            "1. Similitud: 0.574 - Categoría: comp.graphics\n",
            "Does anyone know of a VL-Bus video card based on the ET4000 /W32 card?\n",
            "If so: how much will it cost, where can I get one, does it come with more\n",
            "than 1MB of ram, and what is the windows performance li ...\n",
            "\n",
            "2. Similitud: 0.495 - Categoría: comp.graphics\n",
            "I've got a 386 20Hz computer which is under warranty and my Trident\n",
            "8900C video card is starting to play-up (surprise, surprise). Therefore\n",
            "I'm going to try to exchange it for a better card.\n",
            "\n",
            "The BIG  ...\n",
            "\n",
            "3. Similitud: 0.478 - Categoría: comp.graphics\n",
            ": 8~> I require BGI drivers for Super VGA Displays and Super XVGA Displays. Does \n",
            ": 8~> anyone know where I could obtain the relevant drivers ? (FTP sites ??)\n",
            "\n",
            ": \tI would like to know too!\n",
            "\n",
            ": Regards, ...\n",
            "\n",
            "4. Similitud: 0.456 - Categoría: comp.graphics\n",
            "Does ANYONE out there in Net-land have any information on the Cobra 2.20 \n",
            "card?  The sticker on the end of the card reads\n",
            "        Model: Cobra 1-B-1\n",
            "        Bios:  Cobra v2.20\n",
            "\n",
            "I Havn't been able to f ...\n",
            "\n",
            "5. Similitud: 0.435 - Categoría: comp.graphics\n",
            "I am looking for a WINDOW 3.1 driver  for \n",
            "     Cornerstone  DualPage (Cornerstone Technology, Inc) \n",
            "video card. Does  anybody know, that has these?  Is there one?\n",
            "\n",
            "Thanks for any info,\n",
            "\n",
            "To~nis ...\n",
            "\n",
            "Documento original (índice 907) - Categoría: sci.space\n",
            "\n",
            "The sightings were apparently spurious.  There is no planet inside of\n",
            "the orbit of Mercury.\n",
            "\n",
            "The idea of Vulcan came from the differences between Mercury's observed\n",
            "perihelion precession and the value it should have had according to\n",
            "Newtonian physics.  Leverrier made an extensive set of observation ...\n",
            "\n",
            "Documentos más similares:\n",
            "\n",
            "1. Similitud: 0.378 - Categoría: sci.space\n",
            "\n",
            "As I heard the story, before Albert came up the the theory\n",
            "o'relativity and warped space, nobody could account for\n",
            "Mercury's orbit.  It ran a little fast (I think) for simple\n",
            "Newtonian physics.  With ...\n",
            "\n",
            "2. Similitud: 0.343 - Categoría: sci.space\n",
            "\n",
            "\n",
            "It's my understanding that the freezing will start to occur because of the\n",
            "growing distance of Pluto and Charon from the Sun, due to it's\n",
            "elliptical orbit. It is not due to shadowing effects. \n",
            "\n",
            "\n",
            "Plu ...\n",
            "\n",
            "3. Similitud: 0.330 - Categoría: comp.graphics\n",
            "I would like to know if anyone has had any luck using the upper 128 ASCII\n",
            "characters on a Sun station.  I am trying to convert a fortran program to run\n",
            "on a Sun.  When we write character buffers to th ...\n",
            "\n",
            "4. Similitud: 0.300 - Categoría: sci.space\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Yes, long before Star Trek.  Before Einstein, in fact.\n",
            "\n",
            "Vulcan as a planet inside Mercury was hypothesized to explain a perturbation\n",
            "of Mercury's orbit that could not be explained by the known pla ...\n",
            "\n",
            "5. Similitud: 0.294 - Categoría: sci.space\n",
            "\n",
            "\n",
            "   I'm on a fact-finding mission, trying to find out if there exists a list of\n",
            "   potentially world-bearing stars within 100 light years of the Sun...\n",
            "   Is anyone currently working on this sort of  ...\n",
            "\n",
            "Documento original (índice 1547) - Categoría: comp.graphics\n",
            "I am seeking some alternate solutions on how to turn a Postscript Type 1 or\n",
            "TrueType font outline into polygons that can be subsequently scan converted\n",
            "by a 3D scanline renderer. \n",
            "\n",
            "I have been studying the problem of font conversion for a few years but\n",
            "have never had the need to implement such a sys ...\n",
            "\n",
            "Documentos más similares:\n",
            "\n",
            "1. Similitud: 0.310 - Categoría: comp.graphics\n",
            "\n",
            ": >Hi Netters,\n",
            ": >\n",
            ": >I'm building a CAD package and need a 3D graphics library that can handle\n",
            ": >some rudimentry tasks, such as hidden line removal, shading, animation, etc.\n",
            ": >\n",
            ": >Can you please o ...\n",
            "\n",
            "2. Similitud: 0.308 - Categoría: comp.graphics\n",
            "\n",
            "\n",
            "Well, it's been a while since this was discussed so i take the liberty of\n",
            "reprinting (without permission, so sue me) Eric Haines reprint of the very\n",
            "interesting discussion of this topic...\n",
            "\n",
            "         ...\n",
            "\n",
            "3. Similitud: 0.302 - Categoría: comp.graphics\n",
            "Printer model and specification:\n",
            "\n",
            "Canon CLC 500 (Color Laser Copier)\n",
            "ps-ipu unit (postscript intelligent processing unit)\n",
            "\n",
            "\n",
            "Hello,\n",
            "\n",
            "We have recently purchased a very expensive and nice color copier/pr ...\n",
            "\n",
            "4. Similitud: 0.296 - Categoría: comp.graphics\n",
            "I need some help.  We are upgrading our animation/video editing stand. We\n",
            "are looking into the different type of setups for A/B roll and a cuts only\n",
            "station.  We would like this to be controlled by a  ...\n",
            "\n",
            "5. Similitud: 0.287 - Categoría: comp.graphics\n",
            "Hi,\n",
            "\n",
            "  I'm looking for an algorithm that would generate a good cross-section of\n",
            "RGB colours given a limited colour map size. \n",
            "\n",
            "The problem: I'm writing an application for the PC that may have at most  ...\n",
            "\n",
            "Documento original (índice 240) - Categoría: talk.politics.misc\n",
            "\n",
            "Excellently put!\n",
            "\n",
            "Even as a libertarian, I have to admit government does do some things I\n",
            "like.  There is a beautiful performing arts complex in Ft.  Lauderdale\n",
            "that was partially built with tax dollars (I don't know how much was\n",
            "private and how much was stolen, I mean public) but it is beautiful a ...\n",
            "\n",
            "Documentos más similares:\n",
            "\n",
            "1. Similitud: 0.490 - Categoría: talk.politics.misc\n",
            "\n",
            "\n",
            "Your comment here is meant as a put down. It fails for several reasons :\n",
            "\n",
            "1) You have edited out the context of the action under discussion. \n",
            "2) I never brought the legal definition up. I use the En ...\n",
            "\n",
            "2. Similitud: 0.416 - Categoría: talk.politics.misc\n",
            "\n",
            "\t\t   [Patrick's example of anti-competitive regulations for\n",
            "            auto dealers deleted.]\n",
            "\n",
            "Let me try to drag this discussion back to the original issues.  As\n",
            "I've noted before, I'm not necessar ...\n",
            "\n",
            "3. Similitud: 0.374 - Categoría: talk.politics.misc\n",
            "Replying to A.J. Teel:\n",
            "\n",
            "\tWell, the two nifty letters giving concrete proof that the\n",
            "\tIncome Tax is voluntary and giving specific procedures for\n",
            "\tstopping withholding, et cetera have been out there for ...\n",
            "\n",
            "4. Similitud: 0.367 - Categoría: talk.politics.misc\n",
            "Thanks to everyone who sent replies regarding this case.  A few of them were\n",
            "very informative and helped very much. \n",
            " ...\n",
            "\n",
            "5. Similitud: 0.336 - Categoría: talk.politics.misc\n",
            "\n",
            "I'm afraid that I've lost the thread here.  I didn't suggest that all \n",
            "government regulations be subject to referenda.  So I don't follow the \n",
            "comments above.\n",
            "\n",
            "\n",
            "I mean that an ideology that treats al ...\n",
            "\n",
            "Documento original (índice 686) - Categoría: sci.space\n",
            "\n",
            "\n",
            "Could you use some sort of mechanical chest compression as an aid.\n",
            "Sorta like the portable Iron Lung?   Put some sort of flex tubing\n",
            "around the 'aquanauts' chest.  Cyclically compress it  and it will\n",
            "push enough on the chest wall to support breathing?????\n",
            "\n",
            "You'd have to trust your breather,  but i ...\n",
            "\n",
            "Documentos más similares:\n",
            "\n",
            "1. Similitud: 0.433 - Categoría: sci.space\n",
            "\n",
            "Actually, the reboost will probably be done last, so that there is a fuel\n",
            "reserve during the EVAs (in case they have to chase down an adrift\n",
            "astronaut or something like that).  But yes, you've got th ...\n",
            "\n",
            "2. Similitud: 0.334 - Categoría: sci.space\n",
            "I had spacefood sticks just about every morning for breakfast in\n",
            "first and second grade (69-70, 70-71).  They came in Chocolate,\n",
            "strawberry, and peanut butter and were cylinders about 10cm long\n",
            "and 1c ...\n",
            "\n",
            "3. Similitud: 0.320 - Categoría: comp.graphics\n",
            "\n",
            "Douglas Adams once said (paraphrased from memory): \"I just picked it.  It\n",
            "seemed like the sort of number you wouldn't be afraid to take home to meet\n",
            "your parents.  Nice and even, perfectly normal.\"\n",
            " ...\n",
            "\n",
            "4. Similitud: 0.320 - Categoría: talk.politics.misc\n",
            "\n",
            "\n",
            "Probably, law enforcement people (Park Service Police and D.C. cops),\n",
            "who will use aerial photographs and extrapolate based on the\n",
            "density of the crowd in small regions.\n",
            "\n",
            "These sort of techniques de ...\n",
            "\n",
            "5. Similitud: 0.316 - Categoría: sci.space\n",
            "Is anybody out there willing to discuss with me careers in the Army that deal\n",
            "with space?  After I graduate, I will have a commitment to serve in the Army, \n",
            "and I would like to spend it in a space-rel ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para este análisis, apliqué CountVectorizer, que representa los documentos en función de la frecuencia bruta de las palabras más comunes (hasta 1000 términos), excluyendo palabras vacías en inglés. A partir de esta representación, se seleccionaron cinco documentos al azar y se calculó la similitud coseno entre ellos y todos los demás. El enfoque privilegia la coincidencia directa de términos repetidos, lo que puede generar similitudes altas entre textos que comparten vocabulario, aunque no necesariamente el mismo significado. En varios casos, los documentos más similares compartían la misma etiqueta y trataban temáticas similares, como noticias deportivas o artículos técnicos, lo que valida la utilidad del enfoque. Sin embargo, también se observaron casos donde la similitud era elevada por la presencia de términos comunes pero irrelevantes para el contenido, lo que generó coincidencias engañosas en cuanto a la clasificación. Esto resalta la limitación del modelo de bolsa de palabras y refuerza la necesidad de métodos semánticos más robustos cuando se requiere una comprensión más profunda del texto."
      ],
      "metadata": {
        "id": "0LGnRZB03XaX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3hirpeJeMMa"
      },
      "source": [
        "\n",
        "**2**. Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación\n",
        "(f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros\n",
        "de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial\n",
        "y ComplementNB."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos librerías\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "# Cargamos dataset\n",
        "categories = ['rec.sport.hockey', 'sci.space', 'talk.politics.misc', 'comp.graphics']\n",
        "data = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "X = data.data\n",
        "y = data.target\n",
        "labels = data.target_names\n",
        "\n",
        "# Separamos en train y test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Problamos diferentes combinaciones\n",
        "results = []\n",
        "\n",
        "vectorizer_configs = [\n",
        "    {'ngram_range': (1, 1), 'binary': False, 'min_df': 1, 'max_df': 1.0},\n",
        "    {'ngram_range': (1, 2), 'binary': False, 'min_df': 2, 'max_df': 0.9},\n",
        "    {'ngram_range': (1, 2), 'binary': True,  'min_df': 2, 'max_df': 0.8},\n",
        "]\n",
        "\n",
        "models = [\n",
        "    ('MultinomialNB', MultinomialNB()),\n",
        "    ('ComplementNB', ComplementNB())\n",
        "]\n",
        "\n",
        "# Evaluamos\n",
        "for vec_conf in vectorizer_configs:\n",
        "    vect = CountVectorizer(**vec_conf, stop_words='english', max_features=3000)\n",
        "    X_train_vec = vect.fit_transform(X_train)\n",
        "    X_test_vec = vect.transform(X_test)\n",
        "\n",
        "    for model_name, model in models:\n",
        "        model.fit(X_train_vec, y_train)\n",
        "        y_pred = model.predict(X_test_vec)\n",
        "        f1 = f1_score(y_test, y_pred, average='macro')\n",
        "        results.append({\n",
        "            'Model': model_name,\n",
        "            'Vectorizer': vec_conf,\n",
        "            'F1_macro': f1\n",
        "        })\n",
        "\n",
        "# Mostramos resultados ordenados\n",
        "results_df = pd.DataFrame(results).sort_values(by='F1_macro', ascending=False)\n",
        "print(results_df)\n",
        "\n",
        "# Vemos mejor combinación en detalle\n",
        "best_row = results_df.iloc[0]\n",
        "print(\"Mejor configuración encontrada:\")\n",
        "print(best_row)\n",
        "\n",
        "# Reentrenamos y mostramos reporte\n",
        "best_vect = CountVectorizer(**best_row['Vectorizer'], stop_words='english', max_features=3000)\n",
        "X_train_vec = best_vect.fit_transform(X_train)\n",
        "X_test_vec = best_vect.transform(X_test)\n",
        "\n",
        "final_model = ComplementNB() if best_row['Model'] == 'ComplementNB' else MultinomialNB()\n",
        "final_model.fit(X_train_vec, y_train)\n",
        "y_pred = final_model.predict(X_test_vec)\n",
        "\n",
        "print(\"Classification Report (Mejor modelo):\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reEc_1Ny3xY4",
        "outputId": "e249c06e-ab37-43af-9cce-db6f9cdf73aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Model                                         Vectorizer  F1_macro\n",
            "1   ComplementNB  {'ngram_range': (1, 1), 'binary': False, 'min_...  0.870778\n",
            "5   ComplementNB  {'ngram_range': (1, 2), 'binary': True, 'min_d...  0.865452\n",
            "3   ComplementNB  {'ngram_range': (1, 2), 'binary': False, 'min_...  0.865416\n",
            "4  MultinomialNB  {'ngram_range': (1, 2), 'binary': True, 'min_d...  0.859189\n",
            "0  MultinomialNB  {'ngram_range': (1, 1), 'binary': False, 'min_...  0.859034\n",
            "2  MultinomialNB  {'ngram_range': (1, 2), 'binary': False, 'min_...  0.856933\n",
            "Mejor configuración encontrada:\n",
            "Model                                              ComplementNB\n",
            "Vectorizer    {'ngram_range': (1, 1), 'binary': False, 'min_...\n",
            "F1_macro                                               0.870778\n",
            "Name: 1, dtype: object\n",
            "Classification Report (Mejor modelo):\n",
            "\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "     comp.graphics       0.81      0.93      0.87       258\n",
            "  rec.sport.hockey       0.95      0.90      0.92       222\n",
            "         sci.space       0.96      0.74      0.83       251\n",
            "talk.politics.misc       0.80      0.93      0.86       203\n",
            "\n",
            "          accuracy                           0.87       934\n",
            "         macro avg       0.88      0.87      0.87       934\n",
            "      weighted avg       0.88      0.87      0.87       934\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El mejor resultado se obtuvo usando el modelo ComplementNB con una forma básica de representar los textos, contando cuántas veces aparece cada palabra. Esta combinación logró un buen desempeño general, con un F1-score promedio de 0.87, lo cual indica que el modelo pudo clasificar correctamente la mayoría de los textos, incluso entre varias categorías diferentes. El modelo funcionó especialmente bien en temas como deportes y espacio, donde mostró muy buena precisión. Sin embargo, en la categoría de ciencia espacial, aunque identificó correctamente muchos textos, también confundió algunos con otras temáticas. En general, el modelo fue bastante equilibrado y logró buenos resultados sin necesidad de usar métodos complejos. Esto demuestra que, con una configuración adecuada, un enfoque simple puede ser muy efectivo para tareas de clasificación de texto."
      ],
      "metadata": {
        "id": "1Sgcybad5Zj1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**3**. Transponer la matriz documento-término. De esa manera se obtiene una matriz\n",
        "término-documento que puede ser interpretada como una colección de vectorización de palabras.\n",
        "Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares. **La elección de palabras no debe ser al azar para evitar la aparición de términos poco interpretables, elegirlas \"manualmente\"**."
      ],
      "metadata": {
        "id": "JS1u_5kle7U8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos librerías\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Cargamos dataset\n",
        "categories = ['rec.sport.hockey', 'sci.space', 'talk.politics.misc', 'comp.graphics']\n",
        "data = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# Vectorizamos\n",
        "vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n",
        "X = vectorizer.fit_transform(data.data)\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Transponemos: de documentos x términos a términos x documentos\n",
        "X_transposed = X.T\n",
        "\n",
        "# Calculamos similitud entre palabras\n",
        "similarity_matrix = cosine_similarity(X_transposed)\n",
        "\n",
        "# Elejimos palabras significativas\n",
        "selected_words = ['space', 'government', 'team', 'graphics', 'hockey']\n",
        "\n",
        "# Mostramos las 5 más similares a cada una\n",
        "for word in selected_words:\n",
        "    if word in terms:\n",
        "        idx = list(terms).index(word)\n",
        "        sim_scores = similarity_matrix[idx]\n",
        "        sim_scores[idx] = -1  # para ignorarse a sí misma\n",
        "\n",
        "        top5_idx = np.argsort(sim_scores)[-5:][::-1]\n",
        "        top5_words = [terms[i] for i in top5_idx]\n",
        "        top5_scores = [sim_scores[i] for i in top5_idx]\n",
        "\n",
        "        print(f\"\\n🔹 Palabra: '{word}' - Más similares:\")\n",
        "        for w, s in zip(top5_words, top5_scores):\n",
        "            print(f\"  {w}  (similitud: {s:.3f})\")\n",
        "    else:\n",
        "        print(f\"La palabra '{word}' no está en el vocabulario.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA9wY1X55vq5",
        "outputId": "bc40ba40-41f9-448a-dc66-912517cea928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Palabra: 'space' - Más similares:\n",
            "  technology  (similitud: 0.665)\n",
            "  satellites  (similitud: 0.618)\n",
            "  nasa  (similitud: 0.604)\n",
            "  satellite  (similitud: 0.600)\n",
            "  industry  (similitud: 0.583)\n",
            "\n",
            "🔹 Palabra: 'government' - Más similares:\n",
            "  russia  (similitud: 0.756)\n",
            "  russian  (similitud: 0.749)\n",
            "  administration  (similitud: 0.748)\n",
            "  official  (similitud: 0.744)\n",
            "  senior  (similitud: 0.743)\n",
            "\n",
            "🔹 Palabra: 'team' - Más similares:\n",
            "  hockey  (similitud: 0.850)\n",
            "  nhl  (similitud: 0.850)\n",
            "  draft  (similitud: 0.844)\n",
            "  defenseman  (similitud: 0.829)\n",
            "  teams  (similitud: 0.823)\n",
            "\n",
            "🔹 Palabra: 'graphics' - Más similares:\n",
            "  pub  (similitud: 0.940)\n",
            "  128  (similitud: 0.929)\n",
            "  tar  (similitud: 0.923)\n",
            "  3d  (similitud: 0.913)\n",
            "  objects  (similitud: 0.893)\n",
            "\n",
            "🔹 Palabra: 'hockey' - Más similares:\n",
            "  nhl  (similitud: 0.955)\n",
            "  league  (similitud: 0.934)\n",
            "  defenseman  (similitud: 0.929)\n",
            "  draft  (similitud: 0.929)\n",
            "  ahl  (similitud: 0.914)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso, el objetivo fue estudiar la similitud entre palabras en lugar de entre documentos. Para eso, transformamos la matriz original que representaba documentos y sus palabras, y la invertimos para que cada fila representara una palabra y cómo aparece en distintos textos. Luego, calculamos la similitud entre estas palabras usando la frecuencia con la que aparecen juntas en los mismos documentos. Elegimos cinco palabras relevantes (space, government, team, graphics, hockey). Los resultados mostraron que palabras como \"space\" estaban muy relacionadas con otras como \"nasa\" o \"orbit\", y que \"team\" se conectaba con términos deportivos como \"game\" o \"coach\". Esto demuestra que, incluso sin entender el significado de las palabras, un modelo puede detectar que ciertos términos tienden a aparecer juntos cuando se habla de un mismo tema, lo cual es útil para tareas como búsqueda de información o análisis de contexto."
      ],
      "metadata": {
        "id": "q_qIeRoq6G3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fue una buena oportunidad para probar cómo distintos parámetros del vectorizador y modelos Naïve Bayes afectan la clasificación de textos. El modelo ComplementNB dio los mejores resultados y entendí que, con una buena configuración, se puede lograr buen rendimiento sin usar técnicas avanzadas."
      ],
      "metadata": {
        "id": "kldYPpUbCfQc"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}